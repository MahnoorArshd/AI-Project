{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mk8HVN_UcxzV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Define features and target\n",
        "X = train_df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
        "y = train_df['Survived']\n",
        "\n",
        "# Preprocessing for numerical features\n",
        "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical features\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 1: Load and Explore Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Display first few rows of train and test datasets\n",
        "print(\"Train Dataset Head:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nTest Dataset Head:\")\n",
        "print(test_df.head())\n",
        "\n",
        "# Display summary information\n",
        "print(\"\\nTrain Dataset Info:\")\n",
        "print(train_df.info())\n",
        "print(\"\\nTest Dataset Info:\")\n",
        "print(test_df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS09di_G1Z98",
        "outputId": "78a324f4-0100-4350-90ee-d85570d25925"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Head:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Test Dataset Head:\n",
            "   PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
            "\n",
            "Train Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Test Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 2: Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define features and target\n",
        "X = train_df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
        "y = train_df['Survived']\n",
        "\n",
        "# Preprocessing for numerical features\n",
        "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical features\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nTraining data shape:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3Ha1qXA1wnW",
        "outputId": "e3b94c44-fb1c-4b80-e059-9a0911fff6d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training data shape: (712, 7)\n",
            "Validation data shape: (179, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3: Model Training and Evaluation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Models to evaluate\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'Support Vector Machine': SVC(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_val)\n",
        "\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    report = classification_report(y_val, y_pred, output_dict=True)\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "\n",
        "    results[model_name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': report['weighted avg']['precision'],\n",
        "        'recall': report['weighted avg']['recall'],\n",
        "        'f1-score': report['weighted avg']['f1-score'],\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae\n",
        "    }\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nModel Evaluation Results:\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_EqYUf52ZCo",
        "outputId": "e7e39cba-513b-4fe8-c4ae-9b65f6a95b38"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation Results:\n",
            "                        accuracy  precision    recall  f1-score      RMSE  \\\n",
            "Logistic Regression     0.798883   0.797830  0.798883  0.797427  0.448461   \n",
            "Decision Tree           0.787709   0.787709  0.787709  0.787709  0.460750   \n",
            "Random Forest           0.804469   0.803641  0.804469  0.803824  0.442189   \n",
            "Gradient Boosting       0.815642   0.816567  0.815642  0.812829  0.429369   \n",
            "Support Vector Machine  0.815642   0.815038  0.815642  0.814040  0.429369   \n",
            "K-Nearest Neighbors     0.810056   0.809558  0.810056  0.808114  0.435826   \n",
            "\n",
            "                             MAE  \n",
            "Logistic Regression     0.201117  \n",
            "Decision Tree           0.212291  \n",
            "Random Forest           0.195531  \n",
            "Gradient Boosting       0.184358  \n",
            "Support Vector Machine  0.184358  \n",
            "K-Nearest Neighbors     0.189944  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 4: Results and Best Model\n",
        "best_model = results_df.sort_values(by='f1-score', ascending=False).iloc[0]\n",
        "\n",
        "print(\"\\nBest Model:\")\n",
        "print(best_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqi244gG2stH",
        "outputId": "bf3990a1-5397-4ab1-cc15-2595ad52abf9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model:\n",
            "accuracy     0.815642\n",
            "precision    0.815038\n",
            "recall       0.815642\n",
            "f1-score     0.814040\n",
            "RMSE         0.429369\n",
            "MAE          0.184358\n",
            "Name: Support Vector Machine, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}